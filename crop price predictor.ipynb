{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941931a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 15 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.1437 - loss: 4.1713\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.4722 - loss: 1.6295\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.6466 - loss: 1.1276\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.7348 - loss: 0.7936\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.7896 - loss: 0.6278\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.8269 - loss: 0.5050\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.8794 - loss: 0.3652\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.8902 - loss: 0.3023\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.9120 - loss: 0.2651\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.9287 - loss: 0.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --- CNN Code for Vegetable Classification ---\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 15\n",
    "\n",
    "# Create and train the CNN model\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Data augmentation and loading\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/HP/OneDrive/Desktop/dataset/Vegetable Images', \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(train_generator, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "cnn_model.save('vegetable_cnn_model.h5')\n",
    "\n",
    "# Function to classify an image using the trained CNN model\n",
    "def classify_vegetable(image_path):\n",
    "    model = load_model('vegetable_cnn_model.h5')\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_vegetable_idx = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "    # Get class labels from the train_generator\n",
    "    class_labels = list(train_generator.class_indices.keys())\n",
    "    class_labels.sort()  # Ensure labels are sorted to match indices\n",
    "\n",
    "    predicted_vegetable = class_labels[predicted_vegetable_idx]\n",
    "\n",
    "    print(f\"Predicted vegetable: {predicted_vegetable}\")\n",
    "    return predicted_vegetable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb625cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "Predicted vegetable: Cucumber\n",
      "Enter the season (e.g., winter, summer): winter\n",
      "Enter the month (e.g., jan, feb): feb\n",
      "Enter the temperature in °C: 23\n",
      "Did any disaster happen in the last 3 months? (yes/no): no\n",
      "Enter the vegetable condition (e.g., fresh, scrap): fresh\n",
      "Predicted Price per kg for Cucumber: 30.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Machine Learning Code (ML part for price prediction) ---\n",
    "\n",
    "# Function to handle one-hot encoding with consistent columns\n",
    "def onehot_encode(df, column, training_columns=None):\n",
    "    dummies = pd.get_dummies(df[column], prefix=column)\n",
    "    df = df.drop(column, axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    # Align the columns if training_columns is provided\n",
    "    if training_columns is not None:\n",
    "        for col in training_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0  # Add missing columns with default value 0\n",
    "        df = df[training_columns]  # Reorder columns to match training\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_inputs(df, scaler=None, expected_columns=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Clean 'Vegetable condition' column\n",
    "    df['Vegetable condition'] = df['Vegetable condition'].replace({'scarp': 'scrap'})\n",
    "\n",
    "    # Ensure the correct spelling for 'Disaster Happen in last 3 months'\n",
    "    df['Disaster Happen in last 3 months'] = df['Disaster Happen in last 3 months'].replace({\n",
    "        'no': 0, 'yes': 1, 'no ': 0\n",
    "    })\n",
    "\n",
    "    # Ordinal encoding for 'Month'\n",
    "    month_mapping = {\n",
    "        'jan': 1, 'feb': 2, 'march': 3, 'apr': 4, 'may': 5, 'june': 6, 'july': 7,\n",
    "        'aug': 8, 'sept': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "    }\n",
    "    df['Month'] = df['Month'].str.lower().map(month_mapping)\n",
    "\n",
    "    # Handle missing values in the 'Month' column\n",
    "    if df['Month'].isnull().any():\n",
    "        if not df['Month'].mode().empty:\n",
    "            df['Month'] = df['Month'].fillna(df['Month'].mode()[0])\n",
    "        else:\n",
    "            df['Month'] = df['Month'].fillna(1)  # Default to January if mode is empty\n",
    "\n",
    "    # Handle missing values in numerical columns\n",
    "    numerical_columns = ['Temp', 'Disaster Happen in last 3 months']\n",
    "    for col in numerical_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    # One-hot encoding for categorical variables\n",
    "    if expected_columns is None:\n",
    "        # First call, use the expected columns from training\n",
    "        df = onehot_encode(df, 'Vegetable')\n",
    "        expected_columns = df.columns.tolist()  # Store the columns for alignment\n",
    "        df = onehot_encode(df, 'Season', expected_columns)\n",
    "        df = onehot_encode(df, 'Vegetable condition', expected_columns)\n",
    "    else:\n",
    "        # Subsequent calls, use the stored expected columns\n",
    "        df = onehot_encode(df, 'Vegetable', expected_columns)\n",
    "        df = onehot_encode(df, 'Season', expected_columns)\n",
    "        df = onehot_encode(df, 'Vegetable condition', expected_columns)\n",
    "\n",
    "    # Ensure all remaining columns are numeric\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # Split df into X and y\n",
    "    if 'Price per kg' in df.columns:\n",
    "        y = df['Price per kg']\n",
    "        X = df.drop('Price per kg', axis=1)\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    # Scaling\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    else:\n",
    "        # Ensure the input has the expected columns\n",
    "        X_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
    "\n",
    "    # Ensure the input has the expected columns\n",
    "    if expected_columns is not None:\n",
    "        for col in expected_columns:\n",
    "            if col not in X_scaled.columns:\n",
    "                X_scaled[col] = 0  # Assign 0 if the column is missing\n",
    "        X_scaled = X_scaled[expected_columns]  # Reorder columns to match expected\n",
    "\n",
    "    return X_scaled, y, scaler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('C:/Users/HP/OneDrive/Desktop/Vegetable_market1.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "X_scaled, y, scaler = preprocess_inputs(data)\n",
    "\n",
    "# Train the XGBoost model\n",
    "ml_model = XGBRegressor()\n",
    "ml_model.fit(X_scaled, y)\n",
    "\n",
    "# Function to predict price\n",
    "def predict_price(predicted_vegetable, season, month, temperature, disaster_happened, condition):\n",
    "    input_data = pd.DataFrame({\n",
    "        'Vegetable': [predicted_vegetable],\n",
    "        'Season': [season],\n",
    "        'Month': [month],\n",
    "        'Temp': [temperature],\n",
    "        'Disaster Happen in last 3 months': [disaster_happened],\n",
    "        'Vegetable condition': [condition]\n",
    "    })\n",
    "\n",
    "    # Preprocess the input data without 'Price per kg'\n",
    "    input_data_processed, _, _ = preprocess_inputs(input_data, scaler=scaler, expected_columns=X_scaled.columns)\n",
    "\n",
    "    # Debugging information\n",
    "#     print(\"Input Data for Prediction:\")\n",
    "#     print(input_data_processed)\n",
    "#     print(\"Columns in Input Data:\", input_data_processed.columns.tolist())\n",
    "\n",
    "    # Predict the price\n",
    "    predicted_price = ml_model.predict(input_data_processed)\n",
    "    return predicted_price[0]\n",
    "\n",
    "# Step 1: Use the DL model to classify the vegetable\n",
    "image_path = 'C:/Users/HP/OneDrive/Desktop/dataset/Vegetable Images/Cucumber/1072.jpg'  # Update with your image path\n",
    "predicted_vegetable = classify_vegetable(image_path)  # Function call to classify the vegetable\n",
    "\n",
    "# Step 2: Get additional user inputs\n",
    "season = input(\"Enter the season (e.g., winter, summer): \").strip().lower()\n",
    "month = input(\"Enter the month (e.g., jan, feb): \").strip().lower()\n",
    "temperature = float(input(\"Enter the temperature in °C: \"))\n",
    "disaster_happened_input = input(\"Did any disaster happen in the last 3 months? (yes/no): \").strip().lower()\n",
    "disaster_happened = 1 if disaster_happened_input == 'yes' else 0\n",
    "condition = input(\"Enter the vegetable condition (e.g., fresh, scrap): \").strip().lower()\n",
    "\n",
    "# Predict the price\n",
    "predicted_price_value = predict_price(predicted_vegetable, season, month, temperature, disaster_happened, condition)\n",
    "print(f'Predicted Price per kg for {predicted_vegetable}: {predicted_price_value:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1e449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553c03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
